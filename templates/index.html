<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Braille Bot</title>
</head>
<body class="center-text" style="background-color: rgb(3, 3, 44);">
    <h1 style="font-size: 90px; color: white; background-color: blue;" id="heading1;">Braille Bot</h1>
    
    <button id="record">Press Space and Speak</button>
    <div id="response"></div>   
    <div id="youtubeVideo">
       <!--<iframe width="560" height="315" src="" frameborder="0" allowfullscreen allow="autoplay"></iframe>
        <audio id="audio" autoplay>

            <source src="/templates/narration.mp3">

        </audio> -->
    </div>
    <style>
       
    #response {
    color: #ffffff;
    font-size: 18px;
    background-color: #0F82FF;
   font-size: medium;
    /* Add other styles as needed */
}
    </style>
    <script>

 

document.addEventListener('keydown', (event)=> {    
   
    if (event.code == "Space"){
       
        recordButton.click();
    }
});

        const recordButton = document.getElementById('record');
        const responseDiv = document.getElementById('response');
        const youtubeVideoDiv = document.getElementById('youtubeVideo');
        const videoPlayer = document.getElementById('videoPlayer');
        const chatContainer = document.getElementById('chatContainer');
var msg = new SpeechSynthesisUtterance();
var voices = window.speechSynthesis.getVoices();
msg.voice = voices[1]; 
msg.volume = 1; // From 0 to 1
msg.rate = 1; // From 0.1 to 10
msg.pitch = 2; // From 0 to 2
msg.text = "Hello, I am your virtual assistant! How can I help you?";
msg.lang = 'en';
speechSynthesis.speak(msg);
      
    

window.onload = function() 
{

 

  
    element.click();
        };



        let recognition;
        recordButton.addEventListener('click', () => {
            if (recognition && recognition.isStarted) {
                updateChatHistory();


                recognition.stop();
                recognition = undefined;
                recordButton.innerText = 'Press Space and Speak';
            } else {
                // Use the Web Speech API to perform speech recognition in the browser
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    recordButton.innerText = 'Listening...';
                };
               
                recognition.onresult = (event) => {
                    const result = event.results[0][0].transcript;
                    responseDiv.innerText = result;

                    sendToServer(result);
                    recognition.stop();
                    recordButton.innerText = 'Press Space and Speak';
                };

                recognition.start();
                recordButton.innerText = 'Listening...';
            }
        });
        let commands = [];
        let responses = [];



        function sendToServer(command) {
            //Fetch to send the command to the Flask backend
            fetch('/process-command', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ command }),
            })
            .then(response => response.json())
            .then(data => {
                responseDiv.innerText = data.response;
                //Web Speech API to perform text-to-speech in the browser
                // Create a new chat history entry with the command
        const commandEntry = command;
        commands.push(commandEntry);

        // Create a new chat history entry with the response
        const responseEntry = data.response;
        responses.push(responseEntry);

        // Update the chat history displays for commands and responses
        updateChatHistory();

                if (data.response.includes('youtube')){
                    // If a YouTube URL is provided, display and play the video
                    youtubeVideoDiv.style.display = 'block';
                    const iframe = youtubeVideoDiv.querySelector('iframe');
                    iframe.src = data.response;
                    data.response = "";
                } else {
                    youtubeVideoDiv.style.display = 'none';
                }
            
                const synthesis = new SpeechSynthesisUtterance(data.response);
                synthesis.pitch = 1;
                synthesis.rate = 0.8;
                synthesis.lang = 'en-US';
              
               
                speechSynthesis.speak(synthesis);
            });
            
            function updateChatHistory() {
    const chatContainer = document.getElementById('chatContainer');

    for (let i = 0; i < Math.min(commands.length, responses.length); i++) {
        const userCommand = document.createElement('div');
        userCommand.classList.add('user-message');
        userCommand.textContent = `User: ${commands[i]}`;
        chatContainer.appendChild(userCommand);

        const botResponse = document.createElement('div');
        botResponse.classList.add('bot-message');
        botResponse.textContent = `Bot: ${responses[i]}`;
        chatContainer.appendChild(botResponse);
    }
}



        }
    </script>
</body>
</html>
