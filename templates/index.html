<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" type="text/css" href="../static/style.css">
    <meta charset="UTF-8">
    <title>Braille Bot</title>
</head>
<body  class="center-text1">
    <h1 class="h1" id="heading1">Braille Bot</h1>
    <button id="record">Press Space and Speak</button>
    <!--div class="responsed" id="response"></div--> 

    <div id="chatContainer" class="conversation-container">
        <div class="command-container"></div>
        <div class="response-container"id="response" ></div>
    </div>
    <script>


//utter = new window.SpeechSynthesisUtterance(" ");

//window.speechSynthesis.cancel();
//window.speechSynthesis.speak(utter);

document.addEventListener('keydown', (event)=> {    
    //console.log(event); // all event related info
    //console.log(event.type);
    //console.log(event.key);
    //console.log(event.code);
    if (event.code == "Space"){
        //console.log("Space pressed");
        recordButton.click();
    }
});

         //window.postMessage()
        const recordButton = document.getElementById('record');
        const responseDiv = document.getElementById('response');
        const youtubeVideoDiv = document.getElementById('youtubeVideo');
        const videoPlayer = document.getElementById('videoPlayer');

        /*function performSpeechSynthesis() {
            alert("Page loaded");
            const synthesiss = new SpeechSynthesisUtterance("Hello, my name is your virtual assistant.");
            synthesiss.pitch = 1;
            synthesiss.rate = 0.8;
            synthesiss.lang = 'en-US';

            // Event listener to handle when speech synthesis is finished
            synthesiss.onend = function(event) {
                alert("Speech synthesis complete");
            };

            // Start speech synthesis
            speechSynthesis.speak(synthesiss);
        }
        // Simulating an asynchronous call with a promise
        new Promise((resolve) => {
            // Simulated delay (you can replace this with an actual async operation)
            setTimeout(resolve, 10);
        }).then(() => {
            performSpeechSynthesis(); // Call the function when the promise is resolved
        });

        var element = document.getElementById('heading1');
    element.addEventListener('click', function() {
        
        const synthesiss = new SpeechSynthesisUtterance("Hello, my name is your virtual assistant.");
            synthesiss.pitch = 1;
            synthesiss.rate = 0.8;
            synthesiss.lang = 'en-US';
            
            // Event listener to handle when speech synthesis is finished
            synthesiss.onend = function(event) {
                console.log("Speech synthesis complete");
            };
            
            // Start speech synthesis
            speechSynthesis.cancel();
            speechSynthesis.speak(synthesiss);

    });*/


    

window.onload = function() {

    var audioelement = document.getElementById('audio');
    audioelement.play();

    
    element.click();
        };



        let recognition;
       

        recordButton.addEventListener('click', () => {
            if (recognition && recognition.isStarted) {
                recognition.stop();
                recognition = undefined;
                recordButton.innerText = 'Press Space and Speak';
            } else {
                // Use the Web Speech API to perform speech recognition in the browser
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    recordButton.innerText = 'Listening...';
                };
               
                recognition.onresult = (event) => {
                    const result = event.results[0][0].transcript;
                    responseDiv.innerText = result;
                    
                    sendToServer(result);
                    recognition.stop();
                    recordButton.innerText = 'Press Space and Speak';
                };

                recognition.start();
                recordButton.innerText = 'Listening...';
            }
        });

        function sendToServer(command) {
            //Fetch to send the command to the Flask backend
            fetch('/process-command', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ command }),
            })
            .then(response => response.json())
            .then(data => {
                responseDiv.innerText = data.response;
                //Web Speech API to perform text-to-speech in the browser
            

                if (data.response.includes('youtube')){
                    // If a YouTube URL is provided, display and play the video
                    youtubeVideoDiv.style.display = 'block';
                    const iframe = youtubeVideoDiv.querySelector('iframe');
                    iframe.src = data.response;
                    data.response = "";
                } else {
                    youtubeVideoDiv.style.display = 'none';
                }
                              
                const synthesis = new SpeechSynthesisUtterance(data.response);
                synthesis.pitch = 1;
                synthesis.rate = 0.8;
                synthesis.lang = 'en-US';
              
               
                speechSynthesis.speak(synthesis);
            });
        }
    </script>
</body>
</html>
